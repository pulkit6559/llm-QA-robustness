{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80e3f7c-3574-4bb9-98c4-f8e0f2c30756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_bert\n",
    "import pprint\n",
    "import re\n",
    "from collections.abc import Iterator\n",
    "from functools import partial\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a195e50-7715-4167-a3c3-24a6043f3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_tempobert import ModelArguments\n",
    "import hf_utils\n",
    "from bert_model import BertModel\n",
    "from transformers import AutoModelForMaskedLM, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c543a64f-e5cd-4af2-8c84-8b20f94e717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_time(sentence, fill_mask_pipelines, print_results=True):\n",
    "    if not isinstance(fill_mask_pipelines, list):\n",
    "        fill_mask_pipelines = [fill_mask_pipelines]\n",
    "    time_tokens = [f\"<{time}>\" for time in fill_mask_pipelines[0].model.config.times]\n",
    "    result_dict = {}\n",
    "    original_sentence = sentence\n",
    "    sentence = \"[MASK] \" + sentence\n",
    "    for model_i, fill_mask in enumerate(fill_mask_pipelines):\n",
    "        fill_result = fill_mask(sentence, targets=time_tokens, truncation=True)\n",
    "        result = {res[\"token_str\"]: res[\"score\"] for res in fill_result}\n",
    "        if len(fill_mask_pipelines) == 1:\n",
    "            result_dict = result\n",
    "        else:\n",
    "            result_dict[model_i] = result\n",
    "        if print_results:\n",
    "            res_str = ', '.join(\n",
    "                f'{token} ({score:.2f})' for token, score in result.items()\n",
    "            )\n",
    "            if len(fill_mask_pipelines) > 1:\n",
    "                print(f\"{model_i}: {original_sentence}: {res_str}\")\n",
    "            else:\n",
    "                print(f\"{original_sentence}: {res_str}\")\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b1fa457-9657-463d-8a7d-f303d3bc7175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 22:02:44.714 | INFO     | hf_utils:load_pretrained_model:123 - Loaded a pretrained model from output/TempoBERT_2023-10-18_14-49-45/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.fill_mask.FillMaskPipeline object at 0x7fae65f7fc40>\n",
      "{'<1990>': 0.3611648976802826, '<2000>': 0.2682936191558838, '<2010>': 0.22784477472305298, '<2020>': 0.05866082385182381}\n"
     ]
    }
   ],
   "source": [
    "result_dict = None\n",
    "tester = test_bert.Tester('output/TempoBERT_2023-10-18_14-49-45/', device=0)\n",
    "for fill_mask_pipeline in tester.fill_mask_pipelines:\n",
    "    print(fill_mask_pipeline)\n",
    "    result_dict = test_bert.predict_time(\n",
    "        'Tracy did not repaire to hir hous that even and withstode Rileys berserkes', fill_mask_pipeline, print_results=False\n",
    "    )\n",
    "    print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75994646-3f14-4bbd-87ec-b752a1b3cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name_or_path, expect_times_in_model=True):\n",
    "    model_args = ModelArguments(model_name_or_path=model_name_or_path)\n",
    "    config_kwargs = {}\n",
    "    model, tokenizer = hf_utils.load_pretrained_model(\n",
    "        model_args,\n",
    "        AutoModelForMaskedLM,\n",
    "        expect_times_in_model=expect_times_in_model,\n",
    "        **config_kwargs,\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99b458bd-570b-45db-86d1-cc2cb5bb43eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 22:23:19.212 | INFO     | hf_utils:load_pretrained_model:123 - Loaded a pretrained model from output/TempoBERT_2023-10-18_14-49-45/\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model('output/TempoBERT_2023-10-18_14-49-45/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e702ae64-1b55-465c-b418-4c9fa67845c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': '[MASK] Tracy did not repaire to hir hous that even and withstode Rileys berserkes', 'time_scores': {'<1990>': 0.3611648976802826, '<2000>': 0.2682936191558838, '<2010>': 0.22784477472305298, '<2020>': 0.05866082385182381}}\n"
     ]
    }
   ],
   "source": [
    "def predict_time(sentence, model, tokenizer, print_results=True):\n",
    "    # if not isinstance(fill_mask_pipelines, list):\n",
    "    #     fill_mask_pipelines = [fill_mask_pipelines]\n",
    "    time_tokens = [f\"<{time}>\" for time in model.config.times]\n",
    "    result_dict = {}\n",
    "    original_sentence = sentence \n",
    "    sentence = \"[MASK] \" + sentence\n",
    "    pret_time_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer, device=0)\n",
    "    out_time_preds = pret_time_mask(sentence, targets=time_tokens)\n",
    "    result = {res[\"token_str\"]: res[\"score\"] for res in out_time_preds}\n",
    "    result_dict = {\"sentence\":sentence, \"time_scores\":result}\n",
    "    print(result_dict)\n",
    "    return result_dict\n",
    "\n",
    "result_dict = predict_time(\n",
    "    'Tracy did not repaire to hir hous that even and withstode Rileys berserkes', model, tokenizer, print_results=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c30a088-ce2b-4791-a252-1bc5d101be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': \"[MASK] Kendall's furry friend was carrying a few extra pounds, so they took it on a five-mile hike to burn off some calories\", 'time_scores': {'<1990>': 0.3623791038990021, '<2000>': 0.31215235590934753, '<2010>': 0.26683083176612854, '<2020>': 0.018203917890787125}}\n"
     ]
    }
   ],
   "source": [
    "def predict_time(sentence, model, tokenizer, print_results=True):\n",
    "    # if not isinstance(fill_mask_pipelines, list):\n",
    "    #     fill_mask_pipelines = [fill_mask_pipelines]\n",
    "    time_tokens = [f\"<{time}>\" for time in model.config.times]\n",
    "    result_dict = {}\n",
    "    original_sentence = sentence \n",
    "    sentence = \"[MASK] \" + sentence\n",
    "    pret_time_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer, device=0)\n",
    "    out_time_preds = pret_time_mask(sentence, targets=time_tokens)\n",
    "    result = {res[\"token_str\"]: res[\"score\"] for res in out_time_preds}\n",
    "    result_dict = {\"sentence\":sentence, \"time_scores\":result}\n",
    "    print(result_dict)\n",
    "    return result_dict\n",
    "\n",
    "result_dict = predict_time(\n",
    "    'Kendall\\'s furry friend was carrying a few extra pounds, so they took it on a five-mile hike to burn off some calories', model, tokenizer, print_results=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69338d4b-b108-46f2-b22d-1b7902517883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': \"[MASK] Kendall's pup was a bit too plump, so they had to walk it for five miles to help it shed some pounds\", 'time_scores': {'<2000>': 0.38748985528945923, '<1990>': 0.2741401195526123, '<2010>': 0.26480770111083984, '<2020>': 0.02392939291894436}}\n"
     ]
    }
   ],
   "source": [
    "def predict_time(sentence, model, tokenizer, print_results=True):\n",
    "    # if not isinstance(fill_mask_pipelines, list):\n",
    "    #     fill_mask_pipelines = [fill_mask_pipelines]\n",
    "    time_tokens = [f\"<{time}>\" for time in model.config.times]\n",
    "    result_dict = {}\n",
    "    original_sentence = sentence \n",
    "    sentence = \"[MASK] \" + sentence\n",
    "    pret_time_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer, device=0)\n",
    "    out_time_preds = pret_time_mask(sentence, targets=time_tokens)\n",
    "    result = {res[\"token_str\"]: res[\"score\"] for res in out_time_preds}\n",
    "    result_dict = {\"sentence\":sentence, \"time_scores\":result}\n",
    "    print(result_dict)\n",
    "    return result_dict\n",
    "\n",
    "result_dict = predict_time(\n",
    "    'Kendall\\'s pup was a bit too plump, so they had to walk it for five miles to help it shed some pounds', model, tokenizer, print_results=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0029f032-5082-4dfc-9b45-e39da0d8fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': \"[MASK]  Kendall's dog was overweight so they walked it five miles.\", 'time_scores': {'<2000>': 0.3820279836654663, '<2010>': 0.2790084183216095, '<1990>': 0.250939279794693, '<2020>': 0.03328210115432739}}\n"
     ]
    }
   ],
   "source": [
    "def predict_time(sentence, model, tokenizer, print_results=True):\n",
    "    # if not isinstance(fill_mask_pipelines, list):\n",
    "    #     fill_mask_pipelines = [fill_mask_pipelines]\n",
    "    time_tokens = [f\"<{time}>\" for time in model.config.times]\n",
    "    result_dict = {}\n",
    "    original_sentence = sentence \n",
    "    sentence = \"[MASK] \" + sentence\n",
    "    pret_time_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer, device=0)\n",
    "    out_time_preds = pret_time_mask(sentence, targets=time_tokens)\n",
    "    result = {res[\"token_str\"]: res[\"score\"] for res in out_time_preds}\n",
    "    result_dict = {\"sentence\":sentence, \"time_scores\":result}\n",
    "    print(result_dict)\n",
    "    return result_dict\n",
    "\n",
    "result_dict = predict_time(\n",
    "    ' Kendall\\'s dog was overweight so they walked it five miles.', model, tokenizer, print_results=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c15f06-7b1d-4687-906b-659e777f842d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
